{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate monetary value for recommendations\n",
    "\n",
    "This notebook checks which recommendations were actually purchased on the 4 test weeks. Based on this the hitrate, the monetary value of the hits (based on article-prices) and the share of predicted turnover is calculated.\n",
    "\n",
    "Finally, the results are stored in a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Load submission data and real purchases in test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission file:\n",
    "df_submission = pd.read_csv('../data/Transformer-Baseline-200000_20220510_submission_wardrobesize_1-3.csv')\n",
    "\n",
    "# Set modelname:\n",
    "model_name = 'transformer-w-baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert prediction-string to list\n",
    "df_submission['prediction2'] = df_submission['prediction'].apply(lambda x: list(x.split(' ')))\n",
    "\n",
    "# Cut prediction-list to 12 elements (only for Marketbasket-Submission necessary)\n",
    "df_submission['prediction_12'] = df_submission['prediction2'].apply(lambda x: x[0:12])\n",
    "\n",
    "# Drop not necessary columns:\n",
    "df_submission = df_submission.drop(columns=['prediction', 'prediction2'])\n",
    "\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transactions:\n",
    "df_trans = pd.read_csv('../data/transactions_train.csv', parse_dates=[0], dtype={'article_id':'string'})\n",
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end date:\n",
    "\n",
    "test_week_no = 4\n",
    "\n",
    "if test_week_no == 1:\n",
    "    start_date = \"2020-08-26\"\n",
    "    end_date = \"2020-09-01\"\n",
    "elif test_week_no == 2:\n",
    "    start_date = \"2020-09-02\"\n",
    "    end_date = \"2020-09-08\"\n",
    "elif test_week_no == 3:\n",
    "    start_date = \"2020-09-09\"\n",
    "    end_date = \"2020-09-15\"\n",
    "else:\n",
    "    start_date = \"2020-09-16\"\n",
    "    end_date = \"2020-09-22\"\n",
    "\n",
    "# Load purchases in test period:\n",
    "df_test_week = df_trans.query(f't_dat >= \"{start_date}\" and t_dat <= \"{end_date}\"').copy()\n",
    "# Drop not necessary columns:\n",
    "df_test_week = df_test_week.drop(columns=['t_dat', 'sales_channel_id'])\n",
    "\n",
    "print(f'Number of purchases in test-week are: {df_test_week.shape[0]}')\n",
    "\n",
    "df_test_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Collect all prices from forecasted products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hits(actual, predicted, prices):\n",
    "    # find items that were both predicted and bought (repeat buys will only appear once though)\n",
    "    isect = np.intersect1d(actual, predicted)\n",
    "    # count taking into account repeat buys\n",
    "    actual = np.array(actual)\n",
    "    prices = np.array(prices)\n",
    "    hits = np.sum([len(actual[actual == x]) for x in predicted])\n",
    "    # collect items and prices\n",
    "    items = []\n",
    "    prices_out = []\n",
    "    for item in isect:\n",
    "        items.extend([item for i in range(len(actual[actual == item]))])\n",
    "        prices_out.extend(prices[actual == item])\n",
    "    return (hits, items, prices_out)\n",
    "\n",
    "# collect bought items per user for test week\n",
    "actually_bought = df_test_week.groupby('customer_id').article_id.apply(list).rename('actually_bought')\n",
    "actually_paid = df_test_week.groupby('customer_id').price.apply(list).rename('actually_paid')\n",
    "# collect associated predictions and concat\n",
    "predicted = df_submission.set_index('customer_id').loc[actually_bought.index, 'prediction_12']\n",
    "df_tmp = pd.concat([actually_bought, predicted, actually_paid], axis=1)\n",
    "# compute intersection of actual vs. prediction (with repeat buys)\n",
    "intersection = df_tmp.apply(lambda row: count_hits(row.actually_bought, row.prediction_12, row.actually_paid)[0], axis=1)\n",
    "# compute list of correctly predicted items\n",
    "correctly_predicted = df_tmp.apply(lambda row: count_hits(row.actually_bought, row.prediction_12, row.actually_paid)[1], axis=1)\n",
    "# drop all users that have no intersection (no hits)\n",
    "intersection = intersection[intersection > 0]\n",
    "correctly_predicted = correctly_predicted.loc[intersection.index]\n",
    "article_list = correctly_predicted.apply(lambda l: ' '.join(l)).str.cat(sep=' ').split(' ')\n",
    "price_list = df_tmp.apply(lambda row: count_hits(row.actually_bought, row.prediction_12, row.actually_paid)[2], axis=1)\n",
    "price_list = price_list.reset_index().set_index('customer_id').loc[intersection.index]\n",
    "price_list = price_list.iloc[:, 0].apply(lambda l: [str(x) for x in l]).apply(lambda s: ' '.join(s)).str.cat(sep=' ').split(' ')\n",
    "price_list = [float(price) for price in price_list]\n",
    "print(f'Number of found prices: {len(price_list)}')\n",
    "print(f'Number of forecasted articles: {len(article_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Calculate turnover & hitrate in test week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'This calculation regards the model \"{model_name}\" in the week between {start_date} and {end_date}.\\n')\n",
    "print(f'Number of purchased articles: {df_test_week.shape[0]}')\n",
    "\n",
    "# Calculate hitrate:\n",
    "hits = len(article_list)\n",
    "sold_articles = df_test_week.shape[0]\n",
    "hitrate = hits/sold_articles\n",
    "\n",
    "# Calculate turnover:\n",
    "turnover_week = df_test_week.price.sum()\n",
    "\n",
    "# Calculate forecasted turnover and share:\n",
    "forecasted_turnover = sum(price_list)\n",
    "forecast_share = forecasted_turnover/turnover_week\n",
    "\n",
    "print(f'The hitrate is: {round(hitrate*100, 2)} %')\n",
    "print(f'Turnover in this week is €: {round(turnover_week, 2)}')\n",
    "print(f'The forecasted turnover is €: {round(forecasted_turnover, 2)}')\n",
    "print(f'\\nWe are able to forecast the following share of turnover:\\n{round(forecast_share*100, 4)} %')\n",
    "\n",
    "# Append to list for saving as csv:\n",
    "result_list = []\n",
    "result_list.append(model_name)\n",
    "result_list.append(start_date)\n",
    "result_list.append(end_date)\n",
    "result_list.append(sold_articles)\n",
    "result_list.append(hits)\n",
    "result_list.append(hitrate)\n",
    "result_list.append(turnover_week)\n",
    "result_list.append(forecasted_turnover)\n",
    "result_list.append(forecast_share)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Save price-list, article-list and results in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert price-list and article-list to dataframe and save as csv:\n",
    "\n",
    "df_forecast = pd.DataFrame(list(zip(article_list, price_list)), columns =['article_id', 'price'])\n",
    "df_forecast.to_csv(f'../data/forecast-results_{model_name}_{start_date}_{end_date}.csv', index=False)\n",
    "df_forecast.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in csv\n",
    "from csv import writer\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append a list as new line to an old csv file\n",
    "append_list_as_row('../data/collection_forecast_results.csv', result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Code-Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NEEDED:\n",
    "# Create wardrobe for testweek:\n",
    "# df_wardrobe_week = df_test_week.groupby('customer_id')[['article_id','price']].aggregate(lambda x: list(x)).reset_index().copy()\n",
    "# df_wardrobe_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through datasets to get forecasted products:\n",
    "#price_list = []\n",
    "#article_list = []\n",
    "# for i in tqdm(range(0,10000)):\n",
    "#for i in tqdm(range(len(df_test_week))):\n",
    "#    df_sub_cust = df_submission.query(f'customer_id == \"{df_test_week.customer_id.iloc[i]}\"')\n",
    "#    if df_test_week.article_id.iloc[i] in df_sub_cust.prediction_12.iloc[0]:\n",
    "#        price_list.append(df_test_week.price.iloc[i])\n",
    "#        article_list.append(df_test_week.article_id.iloc[i])\n",
    "\n",
    "\n",
    "#print(f'Number of found prices: {len(price_list)}')\n",
    "#print(f'Number of forecasted articles: {len(article_list)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34347bbd04d675869165b2d6090539280e372b71c1dfdbcf2e17d3e5aff2bc3e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
