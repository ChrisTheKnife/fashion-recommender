{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennart/anaconda3/envs/zoolander/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/lennart/anaconda3/envs/zoolander/lib/python3.9/site-packages/implicit/gpu/__init__.py:13: UserWarning: CUDA extension is built, but disabling GPU support because of 'Cuda Error: CUDA driver version is insufficient for CUDA runtime version (/home/conda/feedstock_root/build_artifacts/implicit_1643471628311/work/./implicit/gpu/utils.h:71)'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import seaborn as sns\n",
    "#from implicit.nearest_neighbours import bm25_weight\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transactions, customer and article data\n",
    "df_trans = pd.read_csv('../data/transactions_train.csv', parse_dates=[0], dtype={'article_id':'string'})\n",
    "df_art = pd.read_csv('../data/articles.csv', dtype={'article_id':'string'})\n",
    "df_customers = pd.read_csv('../data/customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude parts of the data to reduce computational expense\n",
    "# test period\n",
    "#df = df_trans.query('t_dat <= \"2020-09-15\"').copy()\n",
    "# only september 2018 and 2019\n",
    "#df = df_trans.query('(t_dat >= \"2018-09-01\" and t_dat < \"2018-10-01\") or (t_dat >= \"2019-09-01\" and t_dat < \"2019-10-01\") or (t_dat >= \"2020-09-01\" and t_dat < \"2020-10-01\")').copy()\n",
    "df = df_trans.query('(t_dat >= \"2018-08-26\" and t_dat < \"2018-09-23\") or (t_dat >= \"2019-08-26\" and t_dat < \"2019-09-22\") or (t_dat >= \"2020-07-25\" and t_dat < \"2020-08-26\")').copy()\n",
    "df_trans = df_trans.query('t_dat < \"2020-08-26\"').copy()\n",
    "#df = df_trans.copy()\n",
    "\n",
    "# exclude users with less than 5 items in history\n",
    "#n_items_per_user = df.groupby('customer_id').count().article_id.rename('n_items')\n",
    "#df['n_items'] = df.customer_id.map(n_items_per_user)\n",
    "#df = df[df.loc[:, 'n_items'] > 4]\n",
    "\n",
    "# keep only users that have bought between 10 and 90 % of their items online\n",
    "#n_items_per_channel = df.groupby(['customer_id', 'sales_channel_id']).count().article_id\n",
    "#tmp1 = n_items_per_channel.reset_index().query('sales_channel_id == 1').set_index('customer_id').article_id.rename('offline_items')\n",
    "#tmp2 = n_items_per_channel.reset_index().query('sales_channel_id == 2').set_index('customer_id').article_id.rename('online_items')\n",
    "#online_fac = pd.concat([tmp1, tmp2], axis=1).fillna(0.0)\n",
    "#online_fac['online_fac'] = online_fac.online_items/(online_fac.online_items + online_fac.offline_items)\n",
    "#df['online_fac'] = df.customer_id.map(online_fac.online_fac).fillna(0.0)\n",
    "#df = df.query('online_fac > 0.1 and online_fac < 0.9').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402190"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.customer_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2344774 entries, 0 to 30744933\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   t_dat             datetime64[ns]\n",
      " 1   customer_id       object        \n",
      " 2   article_id        string        \n",
      " 3   price             float64       \n",
      " 4   sales_channel_id  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(1), string(1)\n",
      "memory usage: 107.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data further by random sampling of users\n",
    "#user_sample = df.groupby('customer_id').sum().sample(371827, random_state=42) #371827\n",
    "#df = df.set_index('customer_id').loc[user_sample.index].reset_index()\n",
    "# now count the number of times a customer bought an item\n",
    "#_ = df.groupby(['customer_id', 'article_id']).count().price.rename('interactions')\n",
    "#df['interactions'] = df.set_index(['customer_id', 'article_id']).index.map(_)\n",
    "df_int = df.groupby(['customer_id', 'article_id']).t_dat.count().reset_index()\n",
    "df_int.rename(columns={'t_dat':'interactions'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int_full = df_trans.groupby(['customer_id', 'article_id']).t_dat.count().reset_index()\n",
    "df_int_full.rename(columns={'t_dat':'interactions'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users_full = df_int_full.customer_id.nunique()\n",
    "n_items_full = df_int_full.article_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 402190 user and 62095 items in 2344774 transactions.\n",
      "Sum of interactions: 2344774\n"
     ]
    }
   ],
   "source": [
    "n_users = df_int.customer_id.nunique()\n",
    "n_items = df_int.article_id.nunique()\n",
    "n_records = len(df)\n",
    "print(f'Sample size: {n_users} user and {n_items} items in {n_records} transactions.')\n",
    "print(f'Sum of interactions: {df_int.interactions.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create utility matrix Y\n",
    "# rows represent items, columns represent users\n",
    "# note: users with no transactions and items never sold are not included\n",
    "n_users = df_int.customer_id.nunique()\n",
    "n_items = df_int.article_id.nunique()\n",
    "user_ids = df_int.customer_id.unique()\n",
    "item_ids = df_int.article_id.unique()\n",
    "\n",
    "item_id_map = dict([(item_id, i) for i, item_id in enumerate(item_ids)])\n",
    "item_id_map_rev = dict([(i, item_id) for i, item_id in enumerate(item_ids)])\n",
    "user_id_map = dict([(user_id, j) for j, user_id in enumerate(user_ids)])\n",
    "user_id_map_rev = dict([(j, user_id) for j, user_id in enumerate(user_ids)])\n",
    "\n",
    "df_int['i'] = df_int.article_id.apply(lambda id: item_id_map[id])\n",
    "df_int['j'] = df_int.customer_id.apply(lambda id: user_id_map[id])\n",
    "\n",
    "# create sparse matrix\n",
    "Y = coo_matrix((df_int.interactions, (df_int['i'], df_int['j'])), shape=(n_items,n_users))\n",
    "#Y = bm25_weight(Y, K1=100, B=0.8)\n",
    "Y_csr = Y.T.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create full utility matrix Y\n",
    "# rows represent items, columns represent users\n",
    "# note: users with no transactions and items never sold are not included\n",
    "n_users_full = df_int_full.customer_id.nunique()\n",
    "n_items_full = df_int_full.article_id.nunique()\n",
    "user_ids_full = df_int_full.customer_id.unique()\n",
    "item_ids_full = df_int_full.article_id.unique()\n",
    "\n",
    "item_id_map_full = dict([(item_id, i) for i, item_id in enumerate(item_ids_full)])\n",
    "item_id_map_rev_full = dict([(i, item_id) for i, item_id in enumerate(item_ids_full)])\n",
    "user_id_map_full = dict([(user_id, j) for j, user_id in enumerate(user_ids_full)])\n",
    "user_id_map_rev_full = dict([(j, user_id) for j, user_id in enumerate(user_ids_full)])\n",
    "\n",
    "df_int_full['i'] = df_int_full.article_id.apply(lambda id: item_id_map_full[id])\n",
    "df_int_full['j'] = df_int_full.customer_id.apply(lambda id: user_id_map_full[id])\n",
    "\n",
    "# create sparse matrix\n",
    "Y_full = coo_matrix((df_int_full.interactions, (df_int_full['i'], df_int_full['j'])), shape=(n_items_full,n_users_full))\n",
    "#Y = bm25_weight(Y, K1=100, B=0.8)\n",
    "Y_full_csr = Y_full.T.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix sparsity:  0.01\n"
     ]
    }
   ],
   "source": [
    "# check sparsity ratio\n",
    "n_total = Y.shape[0]*Y.shape[1]\n",
    "n_ratings = Y.nnz\n",
    "sparsity = n_ratings/n_total\n",
    "print('Matrix sparsity: ', round(sparsity*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix sparsity:  0.02\n"
     ]
    }
   ],
   "source": [
    "# check sparsity ratio\n",
    "n_total = Y_full.shape[0]*Y_full.shape[1]\n",
    "n_ratings = Y_full.nnz\n",
    "sparsity = n_ratings/n_total\n",
    "print('Matrix sparsity: ', round(sparsity*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [13:05<00:00, 26.17s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AlternatingLeastSquares(factors=1280, regularization=0.01, num_threads=0, iterations=30)\n",
    "model.fit(2 * Y_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [48:56<00:00, 97.90s/it]\n"
     ]
    }
   ],
   "source": [
    "model_full = AlternatingLeastSquares(factors=1280, regularization=0.01, num_threads=0, iterations=30)\n",
    "model_full.fit(2 * Y_full_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_id = user_ids[0]\n",
    "#print(len(user_ids), user_id)\n",
    "#print(Y_csr.shape, Y_csr[user_id_map[user_id], :])\n",
    "#ids, scores = model.recommend(user_id_map[user_id], Y_csr[user_id_map[user_id]], N=12, filter_already_liked_items=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#items = [item_id_map_rev[idx] for idx in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict full batch of users\n",
    "user_idx = [user_id_map[id] for id in user_ids]\n",
    "ids, scores = model.recommend(user_idx, Y_csr[user_idx], N=12, filter_already_liked_items=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_diff = df_trans.set_index('customer_id').drop(user_ids, axis=0).reset_index().customer_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937470"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_ids_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx_diff = [user_id_map_full[id] for id in user_ids_diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use full model to predict customers not considered by the \"local\" model\n",
    "ids_diff, scores_diff = model_full.recommend(user_idx_diff, Y_full_csr[user_idx_diff], N=12, filter_already_liked_items=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from matrix indices to item ids\n",
    "tmp = pd.DataFrame(ids, index=user_ids)\n",
    "tmp = tmp.apply(lambda s: ' '.join(s.apply(lambda id: item_id_map_rev[id])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = pd.DataFrame(ids_diff, index=user_ids_diff)\n",
    "tmp2 = tmp2.apply(lambda s: ' '.join(s.apply(lambda id: item_id_map_rev_full[id])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat([tmp, tmp2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339660"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1339660 1339660\n",
      "1339660\n"
     ]
    }
   ],
   "source": [
    "# make frame containing all available individualized recommendations and join with customer table\n",
    "ids_all = np.hstack([user_ids, user_ids_diff])\n",
    "print(len(ids_all), len(np.unique(ids_all)))\n",
    "submission = pd.DataFrame({'prediction':predictions}, index=ids_all)\n",
    "print(submission.index.nunique())\n",
    "submission = df_customers.join(submission, on='customer_id', how='left').set_index('customer_id')\n",
    "#submission = pd.concat([df_customers.set_index('customer_id'), submission], axis=1)\n",
    "\n",
    "# now fill empty predictions with baseline\n",
    "baseline_prediction = '0706016001 0706016002 0372860001 0610776002 0759871002 0464297007 0372860002 0610776001 0399223001 0706016003 0720125001 0156231001'\n",
    "submission.fillna(baseline_prediction, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371980"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[:, 'prediction'].to_csv('../data/seponly_noweights_lowreg_split-model_test-no-testweeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "fig, axs = plt.subplots(4, 4, figsize=(25, 20))\n",
    "c = 0\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax = axs[i][j]\n",
    "        if i == 0:\n",
    "            ax.set_title(article_name)\n",
    "            fname = article_id + '.jpg'\n",
    "            subdir = fname[0:3]\n",
    "            full_path = os.path.join('../data', 'images', subdir, fname)\n",
    "        else:\n",
    "            fname = similar_items[c] + '.jpg'\n",
    "            subdir = fname[0:3]\n",
    "            full_path = os.path.join('../data', 'images', subdir, fname)\n",
    "            ax.set_title(item_names[similar_items[c]])\n",
    "            c += 1\n",
    "         \n",
    "        if os.path.exists(full_path):\n",
    "            img = mpimg.imread(full_path)\n",
    "            ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "129451d5ecfcad708505d1c263bb0bf4b726fa76bd506b0e8917196eb419b67c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('zoolander')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
