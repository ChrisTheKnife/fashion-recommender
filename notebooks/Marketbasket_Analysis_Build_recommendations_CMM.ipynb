{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build recommendations and submission file (for Marketbasket Analysis)\n",
    "\n",
    "This notebook generates recommendation for customer_ids based on the association rules from marketbasket analysis and stores them in a submission file (csv). \n",
    "* Customer_ids where no recommendations could be associated based on association rules are filled with top12-recommendations.\n",
    "* All customer_ids which have less than 12 recommendations are completed with top12-recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Load data from association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load association results:\n",
    "\n",
    "association_results_df = pd.read_csv('../data/20220510_table_association_results_wardrobesize_2-20_wo_none.csv', \\\n",
    "    index_col=0,  dtype={'antecedants':'string', 'consequents':'string'})\n",
    "\n",
    "association_results_df.sort_values('lift', ascending=False, inplace=True)\n",
    "association_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Generate wardrobe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction dataset:\n",
    "df_trans = pd.read_csv('../data/transactions_train.csv', dtype={'article_id':'string'})\n",
    "# Train test split:\n",
    "df_trans_train = df_trans.query('t_dat < \"2020-09-16\"').copy()\n",
    "# Drop not necessary columns:\n",
    "df_trans_red = df_trans_train.drop(columns=['t_dat', 'price', 'sales_channel_id']).copy()\n",
    "# Generate wardrobe:\n",
    "df_wardrobe = df_trans_red.groupby('customer_id')['article_id'].aggregate(lambda x: list(x)).reset_index()\n",
    "\n",
    "df_wardrobe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse wardrobe article_ids to focus on the last bought items:\n",
    "df_wardrobe['wardrobe_reverse'] = df_wardrobe['article_id'].apply(lambda x: list(reversed(x)))\n",
    "df_wardrobe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'number of articles' column (propably needed to generate smaller dataset) and sort descending:\n",
    "\n",
    "df_wardrobe['no_articles'] = df_wardrobe.article_id.apply(lambda x: len(x))\n",
    "df_wardrobe.sort_values('no_articles', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select a sample for testing code\n",
    "# df_sample = df_wardrobe.sample(n=10000, random_state=42).copy()\n",
    "# df_sample.sort_values('no_articles', ascending=False)\n",
    "\n",
    "# Since no sample is necessary df_sample will be df_wardrobe:\n",
    "df_sample = df_wardrobe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del [[df_trans,df_trans_red, df_trans_train, df_wardrobe]]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Assign product recommendations based on current wardrobes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate empty column for recommendation\n",
    "df_sample['reco'] = df_sample.apply(lambda x: [], axis=1)\n",
    "\n",
    "# Generate empty column for recommendation including lift:\n",
    "df_sample['reco_lift'] = df_sample.apply(lambda x: [], axis=1)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append consequents as list\n",
    "# Info: needed 186 minutes for wardrobes between 2-20 products.\n",
    "\n",
    "# ON REVERSED WARDROBES\n",
    "# Higher focus on last purchased articles\n",
    "\n",
    "for i in tqdm(range(len(df_sample))):\n",
    "    for j in range(len(association_results_df)):\n",
    "        if association_results_df.antecedants.iloc[j] in df_sample.wardrobe_reverse.iloc[i]:\n",
    "            if association_results_df.consequents.iloc[j] not in df_sample.wardrobe_reverse.iloc[i]:\n",
    "                df_sample['reco'].iloc[i].append(association_results_df.consequents.iloc[j])\n",
    "                # Append consequents and corresponding lift as tuples if needed:\n",
    "                df_sample['reco_lift'].iloc[i].append((association_results_df.consequents.iloc[j], association_results_df.lift.iloc[j]))\n",
    "\n",
    "# ON NOT REVERSED WARDROBES:\n",
    "\n",
    "# for i in tqdm(range(len(df_sample))):\n",
    "#     for j in range(len(association_results_df)):\n",
    "#         if association_results_df.antecedants.iloc[j] in df_sample.article_id.iloc[i]:\n",
    "#             if association_results_df.consequents.iloc[j] not in df_sample.article_id.iloc[i]:\n",
    "#                 df_sample['reco'].iloc[i].append(association_results_df.consequents.iloc[j])\n",
    "#                 # Append consequents and corresponding lift as tuples if needed:\n",
    "#                 df_sample['reco_lift'].iloc[i].append((association_results_df.consequents.iloc[j], association_results_df.lift.iloc[j]))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe im reasonable inputs:\n",
    "df_sample.sort_values('no_articles', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column which shows the number of recommendations for each customer_id:\n",
    "df_sample['no_reco'] = df_sample.reco.apply(lambda x: len(x))\n",
    "df_sample.sort_values('no_reco', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customer_ids with at least X recommendations:\n",
    "print(\"The dataset includes...\")\n",
    "print(f\"- {df_sample[df_sample['no_reco']>0].shape[0]} customers with at least 1 recommendation\")\n",
    "print(f\"- {df_sample[df_sample['no_reco']>5].shape[0]} customers with at least 6 recommendations\")\n",
    "print(f\"- {df_sample[df_sample['no_reco']>12].shape[0]} customers with more than 12 recommendations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reco-column (\"prediction\") which stores recos in one string:\n",
    "# df_sample['prediction'] = ' '.join(df_sample['reco'])\n",
    "df_sample['prediction'] = df_sample.reco.apply(lambda x: ' '.join(x))\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store recommendations as csv:\n",
    "df_sample.to_csv('../data/20220510_train_all_cust_recommendations_wardrobesize_2-20_wo_none_reverse_wr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Generate submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission train file (only customer_ids which exist in train dataset):\n",
    "df_submission_train = df_sample.drop(columns=['article_id', 'reco', 'no_articles', 'no_reco', 'wardrobe_reverse', 'reco_lift'])\n",
    "df_submission_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample_submission to get all customer_ids and drop sample predictions:\n",
    "df_sample_sub = pd.read_csv('../data/baseline_sample_submission.csv')\n",
    "df_sample_sub.drop(columns=['prediction'], inplace=True)\n",
    "df_sample_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate full submission file with all customer_ids:\n",
    "df_submission_test = pd.merge(df_sample_sub, df_submission_train, how= 'left', on=\"customer_id\")\n",
    "df_submission_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill up with baseline-model recommendations (top12 most sold articles):\n",
    "\n",
    "df_submission_test_baseline = df_submission_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \" 0706016001 0706016002 0372860001 0610776002 0759871002 0464297007 0372860002 0610776001 0399223001 0706016003 0720125001 0156231001\"\n",
    "df_submission_test_baseline['prediction'] = df_submission_test_baseline['prediction'] + baseline\n",
    "df_submission_test_baseline['prediction'].fillna(value=baseline, inplace=True)\n",
    "df_submission_test_baseline['prediction'] = df_submission_test_baseline['prediction'].str.strip()\n",
    "df_submission_test_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_test_baseline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBA with baseline: Store submission file as csv:\n",
    "df_submission_test_baseline.to_csv('../data/MBA-Baseline-WR-Reverse_20220510_submission_wardrobesize_2-20.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBA without baseline: Store submission file as csv:\n",
    "df_submission_test.to_csv('../data/MBA-wo-Baseline-WR-Reverse_20220510_submission_wardrobesize_2-20.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_test.info()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34347bbd04d675869165b2d6090539280e372b71c1dfdbcf2e17d3e5aff2bc3e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
